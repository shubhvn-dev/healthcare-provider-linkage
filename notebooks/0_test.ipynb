{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0f3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB_DIR = \"../lib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "352bb995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessing.py from: ../lib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If notebook lives in notebooks/, go up one level and into lib/\n",
    "BASE_DIR = os.path.dirname(os.getcwd())  # adjust if needed\n",
    "LIB_DIR = \"../lib\"\n",
    "\n",
    "if LIB_DIR not in sys.path:\n",
    "    sys.path.insert(0, LIB_DIR)\n",
    "\n",
    "from preprocessing import (\n",
    "    clean_name,\n",
    "    soundex_code,\n",
    "    metaphone_code,\n",
    "    clean_street,\n",
    "    clean_city,\n",
    "    clean_state,\n",
    "    normalize_zip5,\n",
    "    is_valid_npi,\n",
    ")\n",
    "\n",
    "print(\"Using preprocessing.py from:\", LIB_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4e580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot check: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Quick check — this should print True\n",
    "print(\"Spot check:\", is_valid_npi(1053656744))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487a5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a55b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "medicare_path = \"../data/MUP_PHY_R25_P05_V20_D23_Prov_Svc.csv\"\n",
    "open_payments_path = \"../data/OP_DTL_GNRL_PGYR2023_P01232026_01102026.csv\"\n",
    "pecos_path = \"../data/Medicare_FFS_Public_Provider_Enrollment_Q3_2025.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab77a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PECOS: 2,936,748 rows, 11 columns\n",
      "Index(['NPI', 'MULTIPLE_NPI_FLAG', 'PECOS_ASCT_CNTL_ID', 'ENRLMT_ID',\n",
      "       'PROVIDER_TYPE_CD', 'PROVIDER_TYPE_DESC', 'STATE_CD', 'FIRST_NAME',\n",
      "       'MDL_NAME', 'LAST_NAME', 'ORG_NAME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pecos = pd.read_csv(pecos_path, low_memory=False, encoding='latin')\n",
    "print(f\"  PECOS: {len(pecos):,} rows, {len(pecos.columns)} columns\")\n",
    "print(pecos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ec8e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Medicare: 9,660,647 rows, 28 columns\n",
      "Index(['Rndrng_NPI', 'Rndrng_Prvdr_Last_Org_Name', 'Rndrng_Prvdr_First_Name',\n",
      "       'Rndrng_Prvdr_MI', 'Rndrng_Prvdr_Crdntls', 'Rndrng_Prvdr_Ent_Cd',\n",
      "       'Rndrng_Prvdr_St1', 'Rndrng_Prvdr_St2', 'Rndrng_Prvdr_City',\n",
      "       'Rndrng_Prvdr_State_Abrvtn', 'Rndrng_Prvdr_State_FIPS',\n",
      "       'Rndrng_Prvdr_Zip5', 'Rndrng_Prvdr_RUCA', 'Rndrng_Prvdr_RUCA_Desc',\n",
      "       'Rndrng_Prvdr_Cntry', 'Rndrng_Prvdr_Type',\n",
      "       'Rndrng_Prvdr_Mdcr_Prtcptg_Ind', 'HCPCS_Cd', 'HCPCS_Desc',\n",
      "       'HCPCS_Drug_Ind', 'Place_Of_Srvc', 'Tot_Benes', 'Tot_Srvcs',\n",
      "       'Tot_Bene_Day_Srvcs', 'Avg_Sbmtd_Chrg', 'Avg_Mdcr_Alowd_Amt',\n",
      "       'Avg_Mdcr_Pymt_Amt', 'Avg_Mdcr_Stdzd_Amt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "medicare = pd.read_csv(medicare_path, low_memory=False)\n",
    "print(f\"  Medicare: {len(medicare):,} rows, {len(medicare.columns)} columns\")\n",
    "print(medicare.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a398cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [\n",
    "    \"Covered_Recipient_Profile_ID\",  # Physician Profile ID\n",
    "    \"Covered_Recipient_First_Name\",\n",
    "    \"Covered_Recipient_Last_Name\",\n",
    "    \"Recipient_Primary_Business_Street_Address_Line1\",\n",
    "    \"Recipient_City\",\n",
    "    \"Recipient_State\",\n",
    "    \"Recipient_Zip_Code\",\n",
    "    \"Covered_Recipient_NPI\",  # may be missing\n",
    "    \"Total_Amount_of_Payment_USDollars\",\n",
    "    \"Date_of_Payment\",\n",
    "    \"Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name\",\n",
    "    \"Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name\",\n",
    "    \"Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State\",\n",
    "    \"Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country\",\n",
    "    \"Program_Year\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19aab53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_21892\\1327469268.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: 14,700,786 rows, 15 columns\n"
     ]
    }
   ],
   "source": [
    "chunk_list = []\n",
    "for chunk in pd.read_csv(open_payments_path, usecols=use_cols, chunksize=200_000):\n",
    "    # Optional: filter, clean, or sample chunk here\n",
    "    chunk_list.append(chunk)\n",
    "\n",
    "# Concatenate after all chunks are collected\n",
    "op = pd.concat(chunk_list, ignore_index=True)\n",
    "print(f\"Loaded dataset: {len(op):,} rows, {len(op.columns)} columns\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d6255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dirty Data Audit — Original (Uncleaned) Datasets ===\n",
      "\n",
      "--- Open Payments ---\n",
      "Total rows:      14,700,786\n",
      "NPI null:        44,233\n",
      "First name null: 31,498\n",
      "Last name null:  31,751\n",
      "Recipient_State null: 617\n",
      "Recipient_City null: 1\n",
      "\n",
      "Column names: ['Covered_Recipient_Profile_ID', 'Covered_Recipient_NPI', 'Covered_Recipient_First_Name', 'Covered_Recipient_Last_Name', 'Recipient_Primary_Business_Street_Address_Line1', 'Recipient_City', 'Recipient_State', 'Recipient_Zip_Code', 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name', 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name', 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_State', 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country', 'Total_Amount_of_Payment_USDollars', 'Date_of_Payment', 'Program_Year']\n",
      "\n",
      "--- Medicare ---\n",
      "Total rows:      9,660,647\n",
      "Rndrng_NPI null: 0\n",
      "Rndrng_Prvdr_First_Name null: 537,099\n",
      "Rndrng_Prvdr_Last_Org_Name null: 0\n",
      "Rndrng_Prvdr_State_Abrvtn null: 0\n",
      "Rndrng_Prvdr_Zip5 null: 1\n",
      "\n",
      "Column names: ['Rndrng_NPI', 'Rndrng_Prvdr_Last_Org_Name', 'Rndrng_Prvdr_First_Name', 'Rndrng_Prvdr_MI', 'Rndrng_Prvdr_Crdntls', 'Rndrng_Prvdr_Ent_Cd', 'Rndrng_Prvdr_St1', 'Rndrng_Prvdr_St2', 'Rndrng_Prvdr_City', 'Rndrng_Prvdr_State_Abrvtn', 'Rndrng_Prvdr_State_FIPS', 'Rndrng_Prvdr_Zip5', 'Rndrng_Prvdr_RUCA', 'Rndrng_Prvdr_RUCA_Desc', 'Rndrng_Prvdr_Cntry', 'Rndrng_Prvdr_Type', 'Rndrng_Prvdr_Mdcr_Prtcptg_Ind', 'HCPCS_Cd', 'HCPCS_Desc', 'HCPCS_Drug_Ind', 'Place_Of_Srvc', 'Tot_Benes', 'Tot_Srvcs', 'Tot_Bene_Day_Srvcs', 'Avg_Sbmtd_Chrg', 'Avg_Mdcr_Alowd_Amt', 'Avg_Mdcr_Pymt_Amt', 'Avg_Mdcr_Stdzd_Amt']\n",
      "\n",
      "--- PECOS ---\n",
      "Total rows:      2,936,748\n",
      "NPI null: 0\n",
      "FIRST_NAME null: 434,402\n",
      "LAST_NAME null: 434,438\n",
      "STATE_CD null: 0\n",
      "ORG_NAME null: 2,502,376\n",
      "\n",
      "Column names: ['NPI', 'MULTIPLE_NPI_FLAG', 'PECOS_ASCT_CNTL_ID', 'ENRLMT_ID', 'PROVIDER_TYPE_CD', 'PROVIDER_TYPE_DESC', 'STATE_CD', 'FIRST_NAME', 'MDL_NAME', 'LAST_NAME', 'ORG_NAME']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Dirty Data Audit — Original (Uncleaned) Datasets ===\\n\")\n",
    "\n",
    "# --- Open Payments ---\n",
    "print(\"--- Open Payments ---\")\n",
    "print(f\"Total rows:      {len(op):,}\")\n",
    "print(f\"NPI null:        {op['Covered_Recipient_NPI'].isna().sum():,}\")\n",
    "print(f\"First name null: {op['Covered_Recipient_First_Name'].isna().sum():,}\")\n",
    "print(f\"Last name null:  {op['Covered_Recipient_Last_Name'].isna().sum():,}\")\n",
    "\n",
    "# Check for columns that exist\n",
    "for col in ['Recipient_State', 'RecipientState', 'Recipient_City', 'RecipientCity',\n",
    "            'Recipient_Zip5', 'RecipientZipCode']:\n",
    "    if col in op.columns:\n",
    "        print(f\"{col} null: {op[col].isna().sum():,}\")\n",
    "\n",
    "print(f\"\\nColumn names: {list(op.columns)}\")\n",
    "\n",
    "# --- Medicare ---\n",
    "print(f\"\\n--- Medicare ---\")\n",
    "print(f\"Total rows:      {len(medicare):,}\")\n",
    "for col in ['Rndrng_NPI', 'NPI']:\n",
    "    if col in medicare.columns:\n",
    "        print(f\"{col} null: {medicare[col].isna().sum():,}\")\n",
    "for col in ['Rndrng_Prvdr_First_Name', 'Rndrng_Prvdr_Last_Org_Name',\n",
    "            'Rndrng_Prvdr_State_Abrvtn', 'Rndrng_Prvdr_Zip5']:\n",
    "    if col in medicare.columns:\n",
    "        print(f\"{col} null: {medicare[col].isna().sum():,}\")\n",
    "\n",
    "print(f\"\\nColumn names: {list(medicare.columns)}\")\n",
    "\n",
    "# --- PECOS ---\n",
    "print(f\"\\n--- PECOS ---\")\n",
    "print(f\"Total rows:      {len(pecos):,}\")\n",
    "for col in ['NPI', 'FIRST_NAME', 'LAST_NAME', 'STATE_CD', 'ORG_NAME']:\n",
    "    if col in pecos.columns:\n",
    "        print(f\"{col} null: {pecos[col].isna().sum():,}\")\n",
    "\n",
    "print(f\"\\nColumn names: {list(pecos.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "168522e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pecos, medicare, op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9314461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-NPI records: 44,233\n",
      "\n",
      "Available fields among no-NPI records:\n",
      "  Has first name:        12,833\n",
      "  Has last name:         12,833\n",
      "  Has both names:        12,833\n",
      "  Has both names + state:12,809\n",
      "  Has both names + zip:  12,809\n",
      "  Has NOTHING (no name): 31,400\n",
      "\n",
      ">>> Matchable (name + state): 12,809\n",
      ">>> Unmatchable (no name):    31,424\n"
     ]
    }
   ],
   "source": [
    "# Isolate the 44K no-NPI records from the ORIGINAL OP data\n",
    "no_npi_raw = op[op['Covered_Recipient_NPI'].isna()].copy()\n",
    "print(f\"No-NPI records: {len(no_npi_raw):,}\\n\")\n",
    "\n",
    "# What do we have to work with?\n",
    "has_first = no_npi_raw['Covered_Recipient_First_Name'].notna()\n",
    "has_last  = no_npi_raw['Covered_Recipient_Last_Name'].notna()\n",
    "has_state = no_npi_raw['Recipient_State'].notna()\n",
    "has_zip   = no_npi_raw['Recipient_Zip_Code'].notna()\n",
    "\n",
    "print(\"Available fields among no-NPI records:\")\n",
    "print(f\"  Has first name:        {has_first.sum():,}\")\n",
    "print(f\"  Has last name:         {has_last.sum():,}\")\n",
    "print(f\"  Has both names:        {(has_first & has_last).sum():,}\")\n",
    "print(f\"  Has both names + state:{(has_first & has_last & has_state).sum():,}\")\n",
    "print(f\"  Has both names + zip:  {(has_first & has_last & has_zip).sum():,}\")\n",
    "print(f\"  Has NOTHING (no name): {(~has_first & ~has_last).sum():,}\")\n",
    "\n",
    "# These are the ones we can attempt fuzzy matching on\n",
    "matchable = no_npi_raw[has_first & has_last & has_state].copy()\n",
    "print(f\"\\n>>> Matchable (name + state): {len(matchable):,}\")\n",
    "print(f\">>> Unmatchable (no name):    {len(no_npi_raw) - len(matchable):,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
